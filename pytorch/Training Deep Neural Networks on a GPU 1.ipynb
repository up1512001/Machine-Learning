{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='data/',download=True,transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img,label = dataset[0]\n",
    "img.shape,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2dcd570c6a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAN80lEQVR4nO3df6hcdXrH8c+ncf3DrBpTMYasNhuRWBWbLRqLSl2RrD9QNOqWDVgsBrN/GHChhEr6xyolEuqP0qAsuYu6sWyzLqgYZVkVo6ZFCF5j1JjU1YrdjV6SSozG+KtJnv5xT+Su3vnOzcyZOZP7vF9wmZnzzJnzcLife87Md879OiIEYPL7k6YbANAfhB1IgrADSRB2IAnCDiRxRD83ZpuP/oEeiwiPt7yrI7vtS22/aftt27d281oAesudjrPbniLpd5IWSNou6SVJiyJia2EdjuxAj/XiyD5f0tsR8U5EfCnpV5Ku6uL1APRQN2GfJekPYx5vr5b9EdtLbA/bHu5iWwC61M0HdOOdKnzjND0ihiQNSZzGA03q5si+XdJJYx5/R9L73bUDoFe6CftLkk61/V3bR0r6kaR19bQFoG4dn8ZHxD7bSyU9JWmKpAci4o3aOgNQq46H3jraGO/ZgZ7ryZdqABw+CDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUii4ymbcXiYMmVKsX7sscf2dPtLly5tWTvqqKOK686dO7dYv/nmm4v1u+66q2Vt0aJFxXU///zzYn3lypXF+u23316sN6GrsNt+V9IeSfsl7YuIs+toCkD96jiyXxQRH9TwOgB6iPfsQBLdhj0kPW37ZdtLxnuC7SW2h20Pd7ktAF3o9jT+/Ih43/YJkp6x/V8RsWHsEyJiSNKQJNmOLrcHoENdHdkj4v3qdqekxyTNr6MpAPXrOOy2p9o++uB9ST+QtKWuxgDUq5vT+BmSHrN98HX+PSJ+W0tXk8zJJ59crB955JHF+nnnnVesX3DBBS1r06ZNK6577bXXFutN2r59e7G+atWqYn3hwoUta3v27Cmu++qrrxbrL7zwQrE+iDoOe0S8I+kvauwFQA8x9AYkQdiBJAg7kARhB5Ig7EASjujfl9om6zfo5s2bV6yvX7++WO/1ZaaD6sCBA8X6jTfeWKx/8sknHW97ZGSkWP/www+L9TfffLPjbfdaRHi85RzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtlrMH369GJ948aNxfqcOXPqbKdW7XrfvXt3sX7RRRe1rH355ZfFdbN+/6BbjLMDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBJM2VyDXbt2FevLli0r1q+44opi/ZVXXinW2/1L5ZLNmzcX6wsWLCjW9+7dW6yfccYZLWu33HJLcV3UiyM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTB9ewD4JhjjinW200vvHr16pa1xYsXF9e9/vrri/W1a9cW6xg8HV/PbvsB2zttbxmzbLrtZ2y/Vd0eV2ezAOo3kdP4X0i69GvLbpX0bEScKunZ6jGAAdY27BGxQdLXvw96laQ11f01kq6uty0Adev0u/EzImJEkiJixPYJrZ5oe4mkJR1uB0BNen4hTEQMSRqS+IAOaFKnQ287bM+UpOp2Z30tAeiFTsO+TtIN1f0bJD1eTzsAeqXtabzttZK+L+l429sl/VTSSkm/tr1Y0u8l/bCXTU52H3/8cVfrf/TRRx2ve9NNNxXrDz/8cLHebo51DI62YY+IRS1KF9fcC4Ae4uuyQBKEHUiCsANJEHYgCcIOJMElrpPA1KlTW9aeeOKJ4roXXnhhsX7ZZZcV608//XSxjv5jymYgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9knulFNOKdY3bdpUrO/evbtYf+6554r14eHhlrX77ruvuG4/fzcnE8bZgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtmTW7hwYbH+4IMPFutHH310x9tevnx5sf7QQw8V6yMjIx1vezJjnB1IjrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcHUVnnnlmsX7PPfcU6xdf3Plkv6tXry7WV6xYUay/9957HW/7cNbxOLvtB2zvtL1lzLLbbL9ne3P1c3mdzQKo30RO438h6dJxlv9LRMyrfn5Tb1sA6tY27BGxQdKuPvQCoIe6+YBuqe3XqtP841o9yfYS28O2W/8zMgA912nYfybpFEnzJI1IurvVEyNiKCLOjoizO9wWgBp0FPaI2BER+yPigKSfS5pfb1sA6tZR2G3PHPNwoaQtrZ4LYDC0HWe3vVbS9yUdL2mHpJ9Wj+dJCknvSvpxRLS9uJhx9sln2rRpxfqVV17ZstbuWnl73OHir6xfv75YX7BgQbE+WbUaZz9iAisuGmfx/V13BKCv+LoskARhB5Ig7EAShB1IgrADSXCJKxrzxRdfFOtHHFEeLNq3b1+xfskll7SsPf/888V1D2f8K2kgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSKLtVW/I7ayzzirWr7vuumL9nHPOaVlrN47eztatW4v1DRs2dPX6kw1HdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2SW7u3LnF+tKlS4v1a665plg/8cQTD7mnidq/f3+xPjJS/u/lBw4cqLOdwx5HdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2w0C7sexFi8abaHdUu3H02bNnd9JSLYaHh4v1FStWFOvr1q2rs51Jr+2R3fZJtp+zvc32G7ZvqZZPt/2M7beq2+N63y6ATk3kNH6fpL+PiD+X9FeSbrZ9uqRbJT0bEadKerZ6DGBAtQ17RIxExKbq/h5J2yTNknSVpDXV09ZIurpHPQKowSG9Z7c9W9L3JG2UNCMiRqTRPwi2T2ixzhJJS7rsE0CXJhx229+W9Iikn0TEx/a4c8d9Q0QMSRqqXoOJHYGGTGjozfa3NBr0X0bEo9XiHbZnVvWZknb2pkUAdWh7ZPfoIfx+Sdsi4p4xpXWSbpC0srp9vCcdTgIzZswo1k8//fRi/d577y3WTzvttEPuqS4bN24s1u+8886WtccfL//KcIlqvSZyGn++pL+V9LrtzdWy5RoN+a9tL5b0e0k/7EmHAGrRNuwR8Z+SWr1Bv7jedgD0Cl+XBZIg7EAShB1IgrADSRB2IAkucZ2g6dOnt6ytXr26uO68efOK9Tlz5nTSUi1efPHFYv3uu+8u1p966qli/bPPPjvkntAbHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IIk04+znnntusb5s2bJiff78+S1rs2bN6qinunz66acta6tWrSque8cddxTre/fu7agnDB6O7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQRJpx9oULF3ZV78bWrVuL9SeffLJY37dvX7FeuuZ89+7dxXWRB0d2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUjCEVF+gn2SpIcknSjpgKShiPhX27dJuknS/1ZPXR4Rv2nzWuWNAehaRIw76/JEwj5T0syI2GT7aEkvS7pa0t9I+iQi7ppoE4Qd6L1WYZ/I/Owjkkaq+3tsb5PU7L9mAXDIDuk9u+3Zkr4naWO1aKnt12w/YPu4FusssT1se7i7VgF0o+1p/FdPtL8t6QVJKyLiUdszJH0gKST9k0ZP9W9s8xqcxgM91vF7dkmy/S1JT0p6KiLuGac+W9KTEXFmm9ch7ECPtQp729N425Z0v6RtY4NefXB30EJJW7ptEkDvTOTT+Ask/Yek1zU69CZJyyUtkjRPo6fx70r6cfVhXum1OLIDPdbVaXxdCDvQex2fxgOYHAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ9HvK5g8k/c+Yx8dXywbRoPY2qH1J9NapOnv7s1aFvl7P/o2N28MRcXZjDRQMam+D2pdEb53qV2+cxgNJEHYgiabDPtTw9ksGtbdB7Uuit071pbdG37MD6J+mj+wA+oSwA0k0Enbbl9p+0/bbtm9toodWbL9r+3Xbm5uen66aQ2+n7S1jlk23/Yztt6rbcefYa6i322y/V+27zbYvb6i3k2w/Z3ub7Tds31Itb3TfFfrqy37r+3t221Mk/U7SAknbJb0kaVFEbO1rIy3YflfS2RHR+BcwbP+1pE8kPXRwai3b/yxpV0SsrP5QHhcR/zAgvd2mQ5zGu0e9tZpm/O/U4L6rc/rzTjRxZJ8v6e2IeCcivpT0K0lXNdDHwIuIDZJ2fW3xVZLWVPfXaPSXpe9a9DYQImIkIjZV9/dIOjjNeKP7rtBXXzQR9lmS/jDm8XYN1nzvIelp2y/bXtJ0M+OYcXCarer2hIb7+bq203j309emGR+YfdfJ9OfdaiLs401NM0jjf+dHxF9KukzSzdXpKibmZ5JO0egcgCOS7m6ymWqa8Uck/SQiPm6yl7HG6asv+62JsG+XdNKYx9+R9H4DfYwrIt6vbndKekyjbzsGyY6DM+hWtzsb7ucrEbEjIvZHxAFJP1eD+66aZvwRSb+MiEerxY3vu/H66td+ayLsL0k61fZ3bR8p6UeS1jXQxzfYnlp9cCLbUyX9QIM3FfU6STdU92+Q9HiDvfyRQZnGu9U042p43zU+/XlE9P1H0uUa/UT+vyX9YxM9tOhrjqRXq583mu5N0lqNntb9n0bPiBZL+lNJz0p6q7qdPkC9/ZtGp/Z+TaPBmtlQbxdo9K3ha5I2Vz+XN73vCn31Zb/xdVkgCb5BByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ/D+f1mbt6t55/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(img[0],cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0039, 0.6039, 0.9922, 0.3529, 0.0000],\n",
       "        [0.0000, 0.5451, 0.9922, 0.7451, 0.0078],\n",
       "        [0.0000, 0.0431, 0.7451, 0.9922, 0.2745],\n",
       "        [0.0000, 0.0000, 0.1373, 0.9451, 0.8824],\n",
       "        [0.0000, 0.0000, 0.0000, 0.3176, 0.9412]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0,10:15,10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_indices(n,val_pct):\n",
    "    # determine size of validation set\n",
    "    n_val = int (val_pct*n)\n",
    "    # creating random permutation of 0 to n-1\n",
    "    indxs = np.random.permutation(n)\n",
    "    # pick first n_val indices for validation set\n",
    "    return indxs[n_val:],indxs[:n_val]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n",
      "Sample validation indices: [57432 18673 44603 38529 40800 10844 37925 41808 39550 42039  3325  3175\n",
      "  3320 26856 31656 19281 40059   919 48293 28309]\n"
     ]
    }
   ],
   "source": [
    "train_indices , val_indices = split_indices(len(dataset),val_pct=.166667)\n",
    "print(len(train_indices) , len(val_indices))\n",
    "print('Sample validation indices:',val_indices[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 12000\n",
      "Sample validation indices: [13910 23476 29911  6339 50033 41272  5790 14529 47788  9962 42732  2955\n",
      " 30967 52587 14742  5515 52620 55139 58830 16409]\n"
     ]
    }
   ],
   "source": [
    "train_indices , val_indices = split_indices(len(dataset),val_pct=.2)\n",
    "print(len(train_indices) , len(val_indices))\n",
    "print('Sample validation indices:',val_indices[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# traning sampler data Loader\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "train_dl = DataLoader(dataset,batch_size,sampler=train_sampler)\n",
    "\n",
    "# validation sampler and data loader\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "valid_dl = DataLoader(dataset,batch_size,sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    \"\"\"Feedforward neural network with 1 hidden layer\"\"\"\n",
    "    def __init__(self,in_size,hidden_size,out_size):\n",
    "        super().__init__()\n",
    "        # hidden layer\n",
    "        self.linear1 = nn.Linear(in_size,hidden_size)\n",
    "        # output layer\n",
    "        self.linear2 = nn.Linear(hidden_size,out_size)\n",
    "        \n",
    "    def forward(self,xb):\n",
    "        # flatten the image tensor\n",
    "        xb = xb.view(xb.size(0),-1)\n",
    "        # get intermediate output using hidden layer\n",
    "        out = self.linear1(xb)\n",
    "        # Apply activation function\n",
    "        out = F.relu(out)\n",
    "        # get predictions using output layer\n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# we need [100,784] matrix\n",
    "for xb , yb in train_dl:\n",
    "    print(xb.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 784])\n"
     ]
    }
   ],
   "source": [
    "# above solution\n",
    "for xb,yb in train_dl:\n",
    "    \n",
    "#     xb = xb.view(100,784) \n",
    "# but every time our batch size would not be same and also 28 X 28 image also become any size in other model \n",
    "# for generalized model we will do \"below\"\n",
    "    xb = xb.view(xb.size(0),-1)\n",
    "#     xb.size(0) will take 100 and -1 will multiply rest other 1 * 28 * 28\n",
    "#     xb = xb.view(xb.size(0),2800)\n",
    "    \n",
    "    print(xb.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.2000, 0.0000, 0.0000, 0.6000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relu will ignor negative values from passed tensor\n",
    "import torch.nn.functional as F\n",
    "t = torch.tensor([1,0.2,-2,-0.9,0.6])\n",
    "t = F.relu(t)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "\n",
    "model = MnistModel(input_size,hidden_size=32,out_size=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 784])\n",
      "torch.Size([32])\n",
      "torch.Size([10, 32])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for t in model.parameters():\n",
    "    print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images.shape : torch.Size([100, 1, 28, 28])\n",
      "Loss: 2.316063404083252\n",
      "Output Shape: torch.Size([100, 10])\n",
      "Sample Outputs:\n",
      " tensor([[ 0.1256,  0.2776, -0.0195, -0.0188, -0.2570,  0.2382, -0.3005, -0.2040,\n",
      "         -0.3261,  0.1099],\n",
      "        [ 0.1862,  0.0999, -0.0664,  0.0311,  0.0262,  0.1509, -0.1772, -0.1278,\n",
      "         -0.1716,  0.0479]])\n",
      "Sum : tensor(1.0000, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_dl:\n",
    "    print('Images.shape :',images.shape)\n",
    "    outputs = model(images)\n",
    "    loss = F.cross_entropy(outputs,labels)\n",
    "    print('Loss:',loss.item())\n",
    "    break\n",
    "    \n",
    "\n",
    "print('Output Shape:',outputs.shape)\n",
    "print('Sample Outputs:\\n',outputs[:2].data)\n",
    "print('Sum :',torch.sum(F.softmax(outputs,dim=1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using GPU\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU is available else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data,device):\n",
    "    \"\"\"move tensor to choosen device\"\"\"\n",
    "    if isinstance(data,(list,tuple)):\n",
    "        return [to_device(x,device)for x in data]\n",
    "    return data.to(device,non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "for images,labels in train_dl:\n",
    "    print(images.shape)\n",
    "    images = to_device(images,device)\n",
    "    print(images.device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self,dl,device):\n",
    "        self.dl=dl\n",
    "        self.device=device\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to devices\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b,self.device)\n",
    "            \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl,device)\n",
    "valid_dl = DeviceDataLoader(valid_dl,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb.device cpu\n",
      "yb: tensor([3, 1, 1, 1, 7, 1, 4, 3, 4, 2, 3, 0, 3, 9, 7, 5, 3, 5, 0, 0, 3, 2, 9, 8,\n",
      "        3, 9, 7, 7, 2, 3, 1, 1, 5, 0, 1, 4, 7, 6, 5, 6, 2, 1, 6, 6, 3, 0, 0, 9,\n",
      "        8, 2, 9, 2, 5, 2, 0, 9, 1, 3, 1, 0, 2, 5, 1, 0, 3, 0, 7, 4, 1, 6, 7, 9,\n",
      "        8, 5, 8, 8, 5, 9, 1, 4, 1, 3, 9, 8, 6, 1, 7, 9, 4, 5, 3, 8, 8, 1, 5, 2,\n",
      "        9, 7, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in valid_dl:\n",
    "    print('xb.device',xb.device)\n",
    "    print('yb:',yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model,loss_func,xb,yb,opt=None,metric=None):\n",
    "    # generate predictions\n",
    "    preds = model(xb)\n",
    "    # calculates loss\n",
    "    loss = loss_func(preds,yb)\n",
    "    \n",
    "    if opt is not None:\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "        # update parameter\n",
    "        opt.step()\n",
    "        # reset gradients\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    metric_result = None\n",
    "    if metric is not None:\n",
    "        # compute metric\n",
    "        metric_result = metric(preds,yb)\n",
    "        \n",
    "    return loss.item(),len(xb),metric_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,loss_fn,valid_dl,metric=None):\n",
    "    with torch.no_grad():\n",
    "        # pass each batch through the model\n",
    "        results = [loss_batch(model,loss_fn,xb,yb,metric=metric) for xb,yb in valid_dl]\n",
    "        # separate losses counts and metrics\n",
    "        losses, nums, metrics = zip(*results)\n",
    "        # total size of dataset\n",
    "        total = np.sum(nums)\n",
    "        # average loss accross batches\n",
    "        avg_loss = np.sum(np.multiply(losses,nums))/ total\n",
    "        avg_metric = None\n",
    "        if metric is not None:\n",
    "            # average of metric accross batches\n",
    "            avg_metric = np.sum(np.multiply(metrics,nums)) / total\n",
    "            \n",
    "    return avg_loss,total,avg_metric \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs,lr,model,loss_fn,train_dl,valid_dl,metric=None,opt_fn=None):\n",
    "    losses , metrics = [] , []\n",
    "    \n",
    "    # Instantiate the optimizer\n",
    "    if opt_fn is None : opt_fn = torch.optim.SGD\n",
    "    opt = opt_fn(model.parameters(),lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # training\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model,loss_fn,xb,yb,opt)\n",
    "        \n",
    "        # Evaluation \n",
    "        result = evaluate(model,loss_fn,valid_dl,metric)\n",
    "        val_loss , total , val_metric = result\n",
    "        \n",
    "        # record the loss & metric\n",
    "        losses.append(val_loss)\n",
    "        metrics.append(val_metric)\n",
    "        \n",
    "        # print process\n",
    "        if metric is None:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}] , Loss: {val_loss}')\n",
    "        else:\n",
    "            print('Epoch [{}/{}] , Loss: {:.4f} , {}:{:.4f}'.format(epoch+1,epochs,val_loss,metric.__name__,val_metric))\n",
    "        \n",
    "    return losses,metrics\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs,labels):\n",
    "    _,preds = torch.max(outputs,dim=1)\n",
    "    return torch.sum(preds==labels).item()/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MnistModel(\n",
       "  (linear1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (linear2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model on GPU\n",
    "model = MnistModel(input_size,hidden_size=32,out_size=num_classes)\n",
    "to_device(model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 2.2957, Accuracy : 0.1379\n"
     ]
    }
   ],
   "source": [
    "val_loss , total , val_acc = evaluate(model,F.cross_entropy,valid_dl,metric=accuracy)\n",
    "print('Loss : {:.4f}, Accuracy : {:.4f}'.format(val_loss,val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] , Loss: 0.2008 , accuracy:0.9401\n",
      "Epoch [2/5] , Loss: 0.1643 , accuracy:0.9500\n",
      "Epoch [3/5] , Loss: 0.1406 , accuracy:0.9582\n",
      "Epoch [4/5] , Loss: 0.1357 , accuracy:0.9597\n",
      "Epoch [5/5] , Loss: 0.1229 , accuracy:0.9637\n"
     ]
    }
   ],
   "source": [
    "losses1, metrics1 = fit(5,0.5,model,F.cross_entropy,train_dl,valid_dl,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] , Loss: 0.1121 , accuracy:0.9668\n",
      "Epoch [2/5] , Loss: 0.1119 , accuracy:0.9668\n",
      "Epoch [3/5] , Loss: 0.1099 , accuracy:0.9669\n",
      "Epoch [4/5] , Loss: 0.1091 , accuracy:0.9677\n",
      "Epoch [5/5] , Loss: 0.1096 , accuracy:0.9669\n"
     ]
    }
   ],
   "source": [
    "losses2 , metrics2 = fit(5,0.1,model,F.cross_entropy,train_dl,valid_dl,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] , Loss: 0.1087 , accuracy:0.9676\n",
      "Epoch [2/5] , Loss: 0.1087 , accuracy:0.9677\n",
      "Epoch [3/5] , Loss: 0.1085 , accuracy:0.9680\n",
      "Epoch [4/5] , Loss: 0.1087 , accuracy:0.9678\n",
      "Epoch [5/5] , Loss: 0.1086 , accuracy:0.9677\n"
     ]
    }
   ],
   "source": [
    "losses3 , metrics3 = fit(5,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy Vs. No. of Epochs')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies = [val_acc] + metrics1 + metrics2 + metrics3\n",
    "plt.plot(accuracies,'-x')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Vs. No. of Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will not go beoyend 96%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
