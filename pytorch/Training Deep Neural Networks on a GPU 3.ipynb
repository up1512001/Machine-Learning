{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "# from torchvision.utils.data.sampler import \n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='data/',download=True,transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "img ,  lab = dataset[15]\n",
    "plt.imshow(img[0],cmap='gray')\n",
    "print('Label:',lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting Indices into validation sets\n",
    "def split_indices(n,val_pct):\n",
    "    # detremine size of validation set\n",
    "    n_val = int(n*val_pct)\n",
    "    # creating random permutations from 0 to n-1\n",
    "    indx = np.random.permutation(n)\n",
    "    # pick first n_val indices for validation set\n",
    "    return indx[n_val:],indx[:n_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices length: 48000\n",
      "Validation indices length: 12000\n"
     ]
    }
   ],
   "source": [
    "train_indices, val_indices = split_indices(len(dataset),val_pct=0.2)\n",
    "print('Train indices length:',len(train_indices))\n",
    "print('Validation indices length:',len(val_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27396, 46782, 20023, 44491, 21707, 16712,  5655, 20987, 40719,\n",
       "       45276, 37441, 48701, 21502, 30854, 16487, 31332,  4608,  2717,\n",
       "       44474, 44263])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11942, 33735, 38101, 17405, 33468, 42590, 12838, 28790, 28640,\n",
       "       47412, 26270, 31101, 50718, 23365, 18368, 57241, 43284, 31300,\n",
       "       40601, 10358])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_indices[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# traning sampler data loder\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "train_dl = DataLoader(dataset,batch_size,sampler=train_sampler)\n",
    "\n",
    "# validation sampler data loder\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "valid_dl = DataLoader(dataset,batch_size,sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    '''feed forward neural network with 2 hidden layers'''\n",
    "    def __init__(self,input_size,hidden_size1,hidden_size2,output_size):\n",
    "        super().__init__()\n",
    "        # hidden layer 1\n",
    "        self.linear1 = nn.Linear(input_size,hidden_size1)\n",
    "        #  hidden layer 2\n",
    "        self.linear2 = nn.Linear(hidden_size1,hidden_size2)\n",
    "        # output layer\n",
    "        self.linear3 = nn.Linear(hidden_size2,output_size)\n",
    "        \n",
    "    def forward(self,xb):\n",
    "        # flatten image tensor\n",
    "        xb = xb.view(xb.size(0),-1)\n",
    "        # getting intermediate output using hidden layer 1\n",
    "        out = self.linear1(xb)\n",
    "        # Applying Activation Function layer 1\n",
    "        out = F.relu(out)\n",
    "        # getting second output using hidden layer 2\n",
    "        out = self.linear2(out)\n",
    "        # Applying Activation Function\n",
    "        out = F.relu(out)\n",
    "        # getting output by third layer\n",
    "        out = self.linear3(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "\n",
    "model = MnistModel(input_size,hidden_size1=64,hidden_size2=32,output_size=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n",
      "torch.Size([64])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32])\n",
      "torch.Size([10, 32])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for t in model.parameters():\n",
    "    print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    '''if cuda found then use GPU else CPU'''\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data,device):\n",
    "    '''if cuda available then move tensors in GPU memory'''\n",
    "    if isinstance(data,(list,tuple)):\n",
    "        return [to_device(x,device) for x in data]\n",
    "    return data.to(device,non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self,dl,device):\n",
    "        self.dl=dl\n",
    "        self.device=device\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to devices\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b,self.device)\n",
    "            \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl,device)\n",
    "valid_dl = DeviceDataLoader(valid_dl,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb.device : cpu\n",
      "yb : tensor([2, 9, 4, 3, 0, 6, 6, 3, 5, 6, 2, 4, 7, 2, 2, 4, 3, 0, 1, 7, 7, 9, 7, 0,\n",
      "        9, 1, 2, 6, 1, 8, 2, 2, 4, 4, 9, 4, 4, 9, 1, 6, 4, 9, 3, 1, 2, 8, 4, 5,\n",
      "        7, 2, 2, 8, 0, 7, 5, 5, 0, 9, 6, 9, 0, 6, 7, 9, 2, 4, 7, 5, 2, 4, 4, 8,\n",
      "        4, 7, 2, 3, 6, 7, 5, 9, 1, 2, 2, 9, 8, 1, 3, 9, 5, 3, 9, 4, 9, 2, 8, 3,\n",
      "        0, 1, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "for xb,yb in valid_dl:\n",
    "    print('xb.device :',xb.device)\n",
    "    print('yb :',yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb.device cpu\n",
      "yb: tensor([6, 0, 7, 3, 6, 9, 8, 2, 7, 2, 3, 0, 7, 6, 7, 6, 8, 8, 2, 1, 8, 2, 8, 1,\n",
      "        2, 5, 3, 6, 6, 1, 7, 2, 7, 5, 7, 2, 0, 4, 9, 1, 3, 7, 1, 7, 1, 8, 5, 4,\n",
      "        7, 2, 4, 2, 5, 0, 6, 8, 7, 3, 8, 1, 2, 6, 7, 6, 8, 2, 7, 9, 4, 2, 5, 2,\n",
      "        8, 0, 6, 1, 4, 1, 3, 5, 3, 6, 3, 5, 4, 1, 1, 2, 8, 6, 7, 3, 2, 5, 3, 3,\n",
      "        5, 0, 8, 7])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in valid_dl:\n",
    "    print('xb.device',xb.device)\n",
    "    print('yb:',yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model,loss_func,xb,yb,opt=None,metric=None):\n",
    "    preds = model(xb)\n",
    "    loss = loss_func(preds,yb)\n",
    "    \n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    metric_result = None\n",
    "    if metric is not None:\n",
    "        metric_result = metric(preds,yb)\n",
    "    \n",
    "    return loss.item(), len(xb),metric_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,loss_fn,valid_dl,metric=None):\n",
    "    with torch.no_grad():\n",
    "        results = [loss_batch(model,loss_fn,xb,yb,metric=metric)for xb,yb in valid_dl]\n",
    "        \n",
    "        losses, nums, metrics = zip(*results)\n",
    "        \n",
    "        total = np.sum(nums)\n",
    "        \n",
    "        avg_loss = np.sum(np.multiply(losses,nums))/total\n",
    "        \n",
    "        avg_metric = None\n",
    "        if metric is not None:\n",
    "            avg_metric = np.sum(np.multiply(metrics,nums))/total\n",
    "        \n",
    "        return avg_loss,total,avg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs,model,lr,loss_fn,train_dl,valid_dl,metric=None,opt_fn=None):\n",
    "    losses , metrics = [] , []\n",
    "    \n",
    "    if opt_fn is None: opt_fn = torch.optim.SGD\n",
    "    opt = opt_fn(model.parameters(),lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for xb,yb in train_dl:\n",
    "            loss_batch(model,loss_fn,xb,yb,opt)\n",
    "            \n",
    "        result = evaluate(model,loss_fn,valid_dl,metric)\n",
    "        val_loss,total,val_metric = result\n",
    "        \n",
    "        losses.append(val_loss)\n",
    "        metrics.append(val_metric)\n",
    "        \n",
    "        if metric is None:\n",
    "            print('Epoch [{}/{}] , Loss : {:.4f}'.format(epoch+1,epochs,val_loss))\n",
    "        else:\n",
    "            print('Epoch [{}/{}] , Loss : {:.4f} {} : {:.4f}'.format(epoch+1,epochs,val_loss,metric.__name__,val_metric))\n",
    "            \n",
    "    return losses,metrics\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs,labels):\n",
    "    _,preds = torch.max(outputs,dim=1)\n",
    "    return torch.sum(preds==labels).item()/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MnistModel(\n",
       "  (linear1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (linear2): Linear(in_features=64, out_features=49, bias=True)\n",
       "  (linear3): Linear(in_features=49, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model on CPU\n",
    "model = MnistModel(input_size,hidden_size1=64,hidden_size2=49,output_size=num_classes)\n",
    "to_device(model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss,total,val_acc = evaluate(model,F.cross_entropy,valid_dl,metric=accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 2.3095740815003714 , Accuracy : 0.07883333333333334\n"
     ]
    }
   ],
   "source": [
    "print('Loss : {} , Accuracy : {}'.format(val_loss,val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] , Loss : 0.3399 accuracy : 0.8986\n",
      "Epoch [2/10] , Loss : 0.2557 accuracy : 0.9249\n",
      "Epoch [3/10] , Loss : 0.2130 accuracy : 0.9396\n",
      "Epoch [4/10] , Loss : 0.1735 accuracy : 0.9508\n",
      "Epoch [5/10] , Loss : 0.1495 accuracy : 0.9576\n",
      "Epoch [6/10] , Loss : 0.1433 accuracy : 0.9573\n",
      "Epoch [7/10] , Loss : 0.1276 accuracy : 0.9622\n",
      "Epoch [8/10] , Loss : 0.1166 accuracy : 0.9649\n",
      "Epoch [9/10] , Loss : 0.1114 accuracy : 0.9665\n",
      "Epoch [10/10] , Loss : 0.1086 accuracy : 0.9673\n"
     ]
    }
   ],
   "source": [
    "losses1,metric1 = fit(10,model,0.1,F.cross_entropy,train_dl,valid_dl,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] , Loss : 0.1000 accuracy : 0.9696\n",
      "Epoch [2/10] , Loss : 0.0995 accuracy : 0.9695\n",
      "Epoch [3/10] , Loss : 0.0985 accuracy : 0.9702\n",
      "Epoch [4/10] , Loss : 0.0987 accuracy : 0.9701\n",
      "Epoch [5/10] , Loss : 0.0981 accuracy : 0.9704\n",
      "Epoch [6/10] , Loss : 0.0983 accuracy : 0.9707\n",
      "Epoch [7/10] , Loss : 0.0979 accuracy : 0.9706\n",
      "Epoch [8/10] , Loss : 0.0976 accuracy : 0.9707\n",
      "Epoch [9/10] , Loss : 0.0970 accuracy : 0.9711\n",
      "Epoch [10/10] , Loss : 0.0971 accuracy : 0.9713\n"
     ]
    }
   ],
   "source": [
    "losses2,metric2 = fit(10,model,0.01,F.cross_entropy,train_dl,valid_dl,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] , Loss : 0.0965 accuracy : 0.9708\n",
      "Epoch [2/10] , Loss : 0.0964 accuracy : 0.9712\n",
      "Epoch [3/10] , Loss : 0.0965 accuracy : 0.9712\n",
      "Epoch [4/10] , Loss : 0.0964 accuracy : 0.9711\n",
      "Epoch [5/10] , Loss : 0.0964 accuracy : 0.9711\n",
      "Epoch [6/10] , Loss : 0.0963 accuracy : 0.9714\n",
      "Epoch [7/10] , Loss : 0.0963 accuracy : 0.9712\n",
      "Epoch [8/10] , Loss : 0.0964 accuracy : 0.9712\n",
      "Epoch [9/10] , Loss : 0.0964 accuracy : 0.9710\n",
      "Epoch [10/10] , Loss : 0.0963 accuracy : 0.9714\n"
     ]
    }
   ],
   "source": [
    "losses3,metric3 = fit(10,model,0.001,F.cross_entropy,train_dl,valid_dl,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses4,metric4 = fit(15,model,0.001,F.cross_entropy,train_dl,valid_dl,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses5,metric5 = fit(5,model,0.01,F.cross_entropy,train_dl,valid_dl,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses6,metric6 = fit(5,model,0.009,F.cross_entropy,train_dl,valid_dl,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses7,metric7 = fit(5,model,0.002,F.cross_entropy,train_dl,valid_dl,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses8,metric8 = fit(10,model,0.0006,F.cross_entropy,train_dl,valid_dl,accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using 784 , 56 , 18 , 10 neural network with SGD got around 0.9705 accuracy  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using 784, 56 ,14, 10 neural network with SGD got around 0.9687"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using 784 , 100 , 10 , 10 neural network with SGD got around 0.9742"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using 784 , 49 , 16 , 10 neural network with SGD got around 0.9694"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using 784 , 64 , 49 , 10 neural network with SGD got around 0.9714"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
