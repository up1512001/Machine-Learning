{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dddadd4ec63743eca846b341e75c8919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/MNIST\\raw\\train-images-idx3-ubyte.gz to data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d56fb88d2ee4e789ff2d6e0072eaee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/MNIST\\raw\\train-labels-idx1-ubyte.gz to data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd131d7415b4349b0bd56c871cde04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd28a656346496fb10b32b41cf2d770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data/MNIST\\raw\n",
      "\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = MNIST(root='data/',download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = MNIST(root='data/',train=False)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x273645B6130>, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAN80lEQVR4nO3df6hcdXrH8c+ncf3DrBpTMYasNhuRWBWbLRqLSl2RrD9QNOqWDVgsBrN/GHChhEr6xyolEuqP0qAsuYu6sWyzLqgYZVkVo6ZFCF5j1JjU1YrdjV6SSozG+KtJnv5xT+Su3vnOzcyZOZP7vF9wmZnzzJnzcLife87Md879OiIEYPL7k6YbANAfhB1IgrADSRB2IAnCDiRxRD83ZpuP/oEeiwiPt7yrI7vtS22/aftt27d281oAesudjrPbniLpd5IWSNou6SVJiyJia2EdjuxAj/XiyD5f0tsR8U5EfCnpV5Ku6uL1APRQN2GfJekPYx5vr5b9EdtLbA/bHu5iWwC61M0HdOOdKnzjND0ihiQNSZzGA03q5si+XdJJYx5/R9L73bUDoFe6CftLkk61/V3bR0r6kaR19bQFoG4dn8ZHxD7bSyU9JWmKpAci4o3aOgNQq46H3jraGO/ZgZ7ryZdqABw+CDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUii4ymbcXiYMmVKsX7sscf2dPtLly5tWTvqqKOK686dO7dYv/nmm4v1u+66q2Vt0aJFxXU///zzYn3lypXF+u23316sN6GrsNt+V9IeSfsl7YuIs+toCkD96jiyXxQRH9TwOgB6iPfsQBLdhj0kPW37ZdtLxnuC7SW2h20Pd7ktAF3o9jT+/Ih43/YJkp6x/V8RsWHsEyJiSNKQJNmOLrcHoENdHdkj4v3qdqekxyTNr6MpAPXrOOy2p9o++uB9ST+QtKWuxgDUq5vT+BmSHrN98HX+PSJ+W0tXk8zJJ59crB955JHF+nnnnVesX3DBBS1r06ZNK6577bXXFutN2r59e7G+atWqYn3hwoUta3v27Cmu++qrrxbrL7zwQrE+iDoOe0S8I+kvauwFQA8x9AYkQdiBJAg7kARhB5Ig7EASjujfl9om6zfo5s2bV6yvX7++WO/1ZaaD6sCBA8X6jTfeWKx/8sknHW97ZGSkWP/www+L9TfffLPjbfdaRHi85RzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtlrMH369GJ948aNxfqcOXPqbKdW7XrfvXt3sX7RRRe1rH355ZfFdbN+/6BbjLMDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBJM2VyDXbt2FevLli0r1q+44opi/ZVXXinW2/1L5ZLNmzcX6wsWLCjW9+7dW6yfccYZLWu33HJLcV3UiyM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTB9ewD4JhjjinW200vvHr16pa1xYsXF9e9/vrri/W1a9cW6xg8HV/PbvsB2zttbxmzbLrtZ2y/Vd0eV2ezAOo3kdP4X0i69GvLbpX0bEScKunZ6jGAAdY27BGxQdLXvw96laQ11f01kq6uty0Adev0u/EzImJEkiJixPYJrZ5oe4mkJR1uB0BNen4hTEQMSRqS+IAOaFKnQ287bM+UpOp2Z30tAeiFTsO+TtIN1f0bJD1eTzsAeqXtabzttZK+L+l429sl/VTSSkm/tr1Y0u8l/bCXTU52H3/8cVfrf/TRRx2ve9NNNxXrDz/8cLHebo51DI62YY+IRS1KF9fcC4Ae4uuyQBKEHUiCsANJEHYgCcIOJMElrpPA1KlTW9aeeOKJ4roXXnhhsX7ZZZcV608//XSxjv5jymYgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9knulFNOKdY3bdpUrO/evbtYf+6554r14eHhlrX77ruvuG4/fzcnE8bZgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtmTW7hwYbH+4IMPFutHH310x9tevnx5sf7QQw8V6yMjIx1vezJjnB1IjrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcHUVnnnlmsX7PPfcU6xdf3Plkv6tXry7WV6xYUay/9957HW/7cNbxOLvtB2zvtL1lzLLbbL9ne3P1c3mdzQKo30RO438h6dJxlv9LRMyrfn5Tb1sA6tY27BGxQdKuPvQCoIe6+YBuqe3XqtP841o9yfYS28O2W/8zMgA912nYfybpFEnzJI1IurvVEyNiKCLOjoizO9wWgBp0FPaI2BER+yPigKSfS5pfb1sA6tZR2G3PHPNwoaQtrZ4LYDC0HWe3vVbS9yUdL2mHpJ9Wj+dJCknvSvpxRLS9uJhx9sln2rRpxfqVV17ZstbuWnl73OHir6xfv75YX7BgQbE+WbUaZz9iAisuGmfx/V13BKCv+LoskARhB5Ig7EAShB1IgrADSXCJKxrzxRdfFOtHHFEeLNq3b1+xfskll7SsPf/888V1D2f8K2kgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSKLtVW/I7ayzzirWr7vuumL9nHPOaVlrN47eztatW4v1DRs2dPX6kw1HdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2SW7u3LnF+tKlS4v1a665plg/8cQTD7mnidq/f3+xPjJS/u/lBw4cqLOdwx5HdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2w0C7sexFi8abaHdUu3H02bNnd9JSLYaHh4v1FStWFOvr1q2rs51Jr+2R3fZJtp+zvc32G7ZvqZZPt/2M7beq2+N63y6ATk3kNH6fpL+PiD+X9FeSbrZ9uqRbJT0bEadKerZ6DGBAtQ17RIxExKbq/h5J2yTNknSVpDXV09ZIurpHPQKowSG9Z7c9W9L3JG2UNCMiRqTRPwi2T2ixzhJJS7rsE0CXJhx229+W9Iikn0TEx/a4c8d9Q0QMSRqqXoOJHYGGTGjozfa3NBr0X0bEo9XiHbZnVvWZknb2pkUAdWh7ZPfoIfx+Sdsi4p4xpXWSbpC0srp9vCcdTgIzZswo1k8//fRi/d577y3WTzvttEPuqS4bN24s1u+8886WtccfL//KcIlqvSZyGn++pL+V9LrtzdWy5RoN+a9tL5b0e0k/7EmHAGrRNuwR8Z+SWr1Bv7jedgD0Cl+XBZIg7EAShB1IgrADSRB2IAkucZ2g6dOnt6ytXr26uO68efOK9Tlz5nTSUi1efPHFYv3uu+8u1p966qli/bPPPjvkntAbHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IIk04+znnntusb5s2bJiff78+S1rs2bN6qinunz66acta6tWrSque8cddxTre/fu7agnDB6O7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQRJpx9oULF3ZV78bWrVuL9SeffLJY37dvX7FeuuZ89+7dxXWRB0d2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUjCEVF+gn2SpIcknSjpgKShiPhX27dJuknS/1ZPXR4Rv2nzWuWNAehaRIw76/JEwj5T0syI2GT7aEkvS7pa0t9I+iQi7ppoE4Qd6L1WYZ/I/Owjkkaq+3tsb5PU7L9mAXDIDuk9u+3Zkr4naWO1aKnt12w/YPu4FusssT1se7i7VgF0o+1p/FdPtL8t6QVJKyLiUdszJH0gKST9k0ZP9W9s8xqcxgM91vF7dkmy/S1JT0p6KiLuGac+W9KTEXFmm9ch7ECPtQp729N425Z0v6RtY4NefXB30EJJW7ptEkDvTOTT+Ask/Yek1zU69CZJyyUtkjRPo6fx70r6cfVhXum1OLIDPdbVaXxdCDvQex2fxgOYHAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ9HvK5g8k/c+Yx8dXywbRoPY2qH1J9NapOnv7s1aFvl7P/o2N28MRcXZjDRQMam+D2pdEb53qV2+cxgNJEHYgiabDPtTw9ksGtbdB7Uuit071pbdG37MD6J+mj+wA+oSwA0k0Enbbl9p+0/bbtm9toodWbL9r+3Xbm5uen66aQ2+n7S1jlk23/Yztt6rbcefYa6i322y/V+27zbYvb6i3k2w/Z3ub7Tds31Itb3TfFfrqy37r+3t221Mk/U7SAknbJb0kaVFEbO1rIy3YflfS2RHR+BcwbP+1pE8kPXRwai3b/yxpV0SsrP5QHhcR/zAgvd2mQ5zGu0e9tZpm/O/U4L6rc/rzTjRxZJ8v6e2IeCcivpT0K0lXNdDHwIuIDZJ2fW3xVZLWVPfXaPSXpe9a9DYQImIkIjZV9/dIOjjNeKP7rtBXXzQR9lmS/jDm8XYN1nzvIelp2y/bXtJ0M+OYcXCarer2hIb7+bq203j309emGR+YfdfJ9OfdaiLs401NM0jjf+dHxF9KukzSzdXpKibmZ5JO0egcgCOS7m6ymWqa8Uck/SQiPm6yl7HG6asv+62JsG+XdNKYx9+R9H4DfYwrIt6vbndKekyjbzsGyY6DM+hWtzsb7ucrEbEjIvZHxAFJP1eD+66aZvwRSb+MiEerxY3vu/H66td+ayLsL0k61fZ3bR8p6UeS1jXQxzfYnlp9cCLbUyX9QIM3FfU6STdU92+Q9HiDvfyRQZnGu9U042p43zU+/XlE9P1H0uUa/UT+vyX9YxM9tOhrjqRXq583mu5N0lqNntb9n0bPiBZL+lNJz0p6q7qdPkC9/ZtGp/Z+TaPBmtlQbxdo9K3ha5I2Vz+XN73vCn31Zb/xdVkgCb5BByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ/D+f1mbt6t55/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image , label = dataset[0]\n",
    "plt.imshow(image,cmap='gray')\n",
    "print('Label:',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAN2UlEQVR4nO3de4xc5XnH8d8Psxi8Nq2NC3XMxYDcAA0tKRuCAFU0KIigFIiipLGq1K0QpkmgiULTIloJxD9FpOAmVQiyixunIVwkjHArq41xotIoAbEQFwwGc6mbGLu41E2xqTC+PP1jj6vF3nlnPefMhX2+H2k1M+eZM+/D4N+emXnn7OuIEICp74h+NwCgNwg7kARhB5Ig7EAShB1I4sheDnaUp8fRGu7lkEAqb+stvRO7PVGtVthtXybpa5KmSfqbiLitdP+jNawP+5I6QwIoeCLWtax1/DLe9jRJ35D0MUlnSVpk+6xOHw9Ad9V5z36epJcj4tWIeEfS/ZKubKYtAE2rE/b5kn427vaWatu72F5ie9T26B7trjEcgDrqhH2iDwEO+e5tRCyLiJGIGBnS9BrDAaijTti3SDpp3O0TJW2t1w6AbqkT9iclLbR9qu2jJH1G0upm2gLQtI6n3iJir+3rJP2TxqbeVkTEc411BqBRtebZI2KNpDUN9QKgi/i6LJAEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ9HTJZnTJ+b/WsvRvV5SXyL75kw8W63duKq+6u/PZ44r1ktNv/Umxvv/ttzt+bByKIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME8+3vAazdeUKyv+fztLWsnHzmz1ti/e255Hl7ndv7YFz11bbE+/NATnT84DlEr7LY3S9opaZ+kvREx0kRTAJrXxJH9tyLijQYeB0AX8Z4dSKJu2EPS92w/ZXvJRHewvcT2qO3RPdpdczgAnar7Mv7CiNhq+3hJa22/EBGPjb9DRCyTtEySjvWcqDkegA7VOrJHxNbqcrukhyWd10RTAJrXcdhtD9uedeC6pEslbWiqMQDNqvMy/gRJD9s+8DjfjYh/bKQrvMspK18t1rcuOaZl7eQB/ibF8juWFutXH/nlYn3WA4832c6U1/E/hYh4VdKvN9gLgC5i6g1IgrADSRB2IAnCDiRB2IEkBnhiBgfs3fYfxfrVy69vWXv0c61Pf5WkeW1OgV391oxi/Yrh/y3WS848qvzY2z66t1if9UDHQ6fEkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCefQo48S9+1LL2t4vKf+v5prkvFusv7/7l8uDD5dNv6zjj67uK9f1dG3lq4sgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzz7FrfrrjxTr+693sf7nc19osp3Dsv/oob6NPRVxZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJJhnn+KOW/7jYv3Hj76/WP/q3+8p1r8y55XD7mmydt36VrE+87KuDT0ltT2y215he7vtDeO2zbG91vZL1eXs7rYJoK7JvIz/lqSDf4feKGldRCyUtK66DWCAtQ17RDwmacdBm6+UtLK6vlLSVc22BaBpnX5Ad0JEbJOk6vL4Vne0vcT2qO3RPdrd4XAA6ur6p/ERsSwiRiJiZEjTuz0cgBY6DfvrtudJUnW5vbmWAHRDp2FfLWlxdX2xpEeaaQdAt7SdZ7d9n6SLJc21vUXSzZJuk/Sg7asl/VTSp7rZJDq3/boLivWff6C8Bvrq2Q+3GaF77wR3PF7+m/Uz1b2/WT8VtQ17RCxqUbqk4V4AdBFflwWSIOxAEoQdSIKwA0kQdiAJTnF9D/CHzi7Wr1r5/Za13zv2r4r7zjjiqDaj9+94sGDVwadkvBtLNh8ejuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATz7O8B/3X2zGL9d2a91LI244gZTbfTMy/eUO594eJiGQfhyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDP/h4wZ0V52eULTvzjlrV/uearxX3nThvuqKdemHfCz/vdwpTCkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCefQo4+dYftaz99ss3FPd9+xfr/b6PNv+CHrrh9pa104fK5+mjWW3/T9teYXu77Q3jtt1i+zXb66ufy7vbJoC6JvNr/VuSLptg+9KIOKf6WdNsWwCa1jbsEfGYpPI6PAAGXp03bNfZfqZ6mT+71Z1sL7E9ant0j3bXGA5AHZ2G/ZuSTpd0jqRtku5odceIWBYRIxExMqTpHQ4HoK6Owh4Rr0fEvojYL2m5pPOabQtA0zoKu+15425+QtKGVvcFMBjazrPbvk/SxZLm2t4i6WZJF9s+R1JI2izp2u61iDqO/e7j5XrdAexi+dLTWp9r/8qn7y7u+/lT/7lYv/esS4r1fc9vKtazaRv2iFg0weZ7utALgC7i67JAEoQdSIKwA0kQdiAJwg4kwSmuqOWIY44p1ttNr5Xs3Hd0+Q5793X82BlxZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJJhnRy0vLP3VNvdo/Weu21m66opifcGm8lLWeDeO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBPPsk3Tk/Pe1rL3z7WnFfd9YdVKxfvw3Op+L7rYjT1tQrD962dI2j9D5ssynPfjfxfr+jh85J47sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE8+yTtPWu1osb/+TM+4v7Lruu9Ry9JH3ntY8X68ObdxXr+9c/37K29yPnFvfdccb0Yv2Tf/j9Yv30oc7n0U/9h2uK9TNeaf3fhcPX9shu+yTbP7C90fZztr9YbZ9je63tl6rL2d1vF0CnJvMyfq+kGyLiTEnnS/qC7bMk3ShpXUQslLSuug1gQLUNe0Rsi4inq+s7JW2UNF/SlZJWVndbKemqLvUIoAGH9QGd7QWSPijpCUknRMQ2aewXgqTjW+yzxPao7dE92l2zXQCdmnTYbc+U9JCkL0XEm5PdLyKWRcRIRIwMqfxhEIDumVTYbQ9pLOj3RsSqavPrtudV9XmStnenRQBNaDv1ZtuS7pG0MSLuHFdaLWmxpNuqy0e60uGA+IW7Z7Ws/dH8DxX3/fr7nizWl9y1rFh/aFfraT9Juue1i1rW7j7ta8V9T60xdSZJ+6J8ound/3NKy9qZf7Kp/NhvvdVRT5jYZObZL5T0WUnP2l5fbbtJYyF/0PbVkn4q6VNd6RBAI9qGPSJ+KMktypc02w6AbuHrskAShB1IgrADSRB2IAnCDiThiOjZYMd6TnzYU+8D/E3Ly/PsM14dKtafu/6uJtvpqWfeebtY/8qC83vUCSTpiVinN2PHhLNnHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAn+lHQDfuWa8vnqR8yYUay/f+bnao0/fPaOlrWnRx6o9dib9pTPKf/yH1xfrE/T07XGR3M4sgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEpzPDkwhnM8OgLADWRB2IAnCDiRB2IEkCDuQBGEHkmgbdtsn2f6B7Y22n7P9xWr7LbZfs72++rm8++0C6NRk/njFXkk3RMTTtmdJesr22qq2NCL+snvtAWjKZNZn3yZpW3V9p+2NkuZ3uzEAzTqs9+y2F0j6oKQnqk3X2X7G9grbs1vss8T2qO3RPdpdr1sAHZt02G3PlPSQpC9FxJuSvinpdEnnaOzIf8dE+0XEsogYiYiRIU2v3zGAjkwq7LaHNBb0eyNilSRFxOsRsS8i9ktaLum87rUJoK7JfBpvSfdI2hgRd47bPm/c3T4haUPz7QFoymQ+jb9Q0mclPWt7fbXtJkmLbJ8jKSRtlnRtF/oD0JDJfBr/Q0kTnR+7pvl2AHQL36ADkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k0dMlm23/p6R/H7dprqQ3etbA4RnU3ga1L4neOtVkb6dExC9NVOhp2A8Z3B6NiJG+NVAwqL0Nal8SvXWqV73xMh5IgrADSfQ77Mv6PH7JoPY2qH1J9NapnvTW1/fsAHqn30d2AD1C2IEk+hJ225fZftH2y7Zv7EcPrdjebPvZahnq0T73ssL2dtsbxm2bY3ut7ZeqywnX2OtTbwOxjHdhmfG+Pnf9Xv685+/ZbU+TtEnSRyVtkfSkpEUR8XxPG2nB9mZJIxHR9y9g2P5NSbskfTsiPlBtu13Sjoi4rfpFOTsi/nRAertF0q5+L+NdrVY0b/wy45KukvT76uNzV+jr0+rB89aPI/t5kl6OiFcj4h1J90u6sg99DLyIeEzSjoM2XylpZXV9pcb+sfRci94GQkRsi4inq+s7JR1YZryvz12hr57oR9jnS/rZuNtbNFjrvYek79l+yvaSfjczgRMiYps09o9H0vF97udgbZfx7qWDlhkfmOeuk+XP6+pH2CdaSmqQ5v8ujIjfkPQxSV+oXq5icia1jHevTLDM+EDodPnzuvoR9i2SThp3+0RJW/vQx4QiYmt1uV3Swxq8pahfP7CCbnW5vc/9/L9BWsZ7omXGNQDPXT+XP+9H2J+UtND2qbaPkvQZSav70MchbA9XH5zI9rCkSzV4S1GvlrS4ur5Y0iN97OVdBmUZ71bLjKvPz13flz+PiJ7/SLpcY5/IvyLpz/rRQ4u+TpP0r9XPc/3uTdJ9GntZt0djr4iulnScpHWSXqou5wxQb38n6VlJz2gsWPP61NtFGntr+Iyk9dXP5f1+7gp99eR54+uyQBJ8gw5IgrADSRB2IAnCDiRB2IEkCDuQBGEHkvg/logB4bokIwwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image , label = dataset[10]\n",
    "plt.imshow(image)\n",
    "print('Label:',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='data/',train=True,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 5\n"
     ]
    }
   ],
   "source": [
    "img_tensor , label = dataset[0]\n",
    "print(img_tensor.shape,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.0039, 0.6039, 0.9922,\n",
      "          0.3529, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5451, 0.9922,\n",
      "          0.7451, 0.0078, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.7451,\n",
      "          0.9922, 0.2745, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1373,\n",
      "          0.9451, 0.8824, 0.6275, 0.4235],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3176, 0.9412, 0.9922, 0.9922],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1765, 0.7294, 0.9922],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0627, 0.3647],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1804, 0.5098, 0.7176],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1529,\n",
      "          0.5804, 0.8980, 0.9922, 0.9922]]])\n",
      "tensor(1.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(img_tensor[:,10:20,5:17])\n",
    "print(torch.max(img_tensor),torch.min(img_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2736ae81280>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASsAAAD4CAYAAAC0ecCBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMD0lEQVR4nO3df6hfdR3H8derbZGuxSIrahM1CUsGtRj+aJDkKu0HC6E/FBYU6UCyNIJw/Rf4Z8QCI7mYKbQmtRIizSZMiaCsu7lKnQOblTdXM2RqBc21V3/c7+R7t++991z2Pefc9+35gMvu98fu5/Xl3r12zj3ne95OIgBY7F7TdwAAaIKyAlACZQWgBMoKQAmUFYASlrfxRW13dojxvPPO62opnXPOOZ2tJUnPPPNMZ2u98MILna0FzCWJR93vNk5dsB175HpjNzEx0ck6knT99dd3tpYkbdmypbO1duzY0dlawFxmKyt2AwGUQFkBKIGyAlACZQWgBMoKQAmUFYASKCsAJVBWAEqgrACU0KisbF9t+6Dtp23f2nYoADjVvGVle5mkb0n6qKSLJV1n++K2gwHAsCZbVpdIejrJoSTHJN0r6ZPtxgKAmZqU1RpJzw7dnhrcN4PtrbYnbU+OKxwAnNTkEjGj3gF92qUakkxImpC6vUQMgP8PTbaspiSdO3R7raTn2okDAKM1KavfSnqn7Qtsv1bStZJ+0m4sAJhp3t3AJMdt3yTp55KWSboryROtJwOAIY0ua5zkAUkPtJwFAGbFGewASqCsAJRAWQEogbICUAJlBaAEygpACZQVgBJaGR8vSW1Meh7lxRdf7GSdPtxwww2drbVz587O1jpx4kRna2HpYMsKQAmUFYASKCsAJVBWAEqgrACUQFkBKIGyAlACZQWgBMoKQAmUFYASmkxkvsv2EduPdxEIAEZpsmV1t6SrW84BAHOat6yS/ELSCx1kAYBZje2qC7a3Sto6rq8HAMPGVlaMjwfQJo4GAiiBsgJQQpNTF3ZK+pWki2xP2f5c+7EAYKZ5f2eV5LouggDAXNgNBFACZQWgBMoKQAmUFYASKCsAJVBWAEqgrACU4DbGvHf53sCVK1d2tZTuv//+ztaSpCuuuKKzta666qrO1tq9e3dna6GeJB51P1tWAEqgrACUQFkBKIGyAlACZQWgBMoKQAmUFYASKCsAJVBWAEqgrACU0OQa7Ofaftj2AdtP2L65i2AAMKzJ3MDjkr6cZJ/tVZL22n4oyZMtZwOAVzUZH384yb7B5y9LOiBpTdvBAGDYgiYy2z5f0npJj454jPHxAFrTuKxsv17SjyTdkuSlUx9nfDyANjU6Gmh7haaLakeSH7cbCQBO1+RooCV9R9KBJN9oPxIAnK7JltVGSZ+WdKXt/YOPj7WcCwBmaDI+/peSRl5mFAC6whnsAEqgrACUQFkBKIGyAlACZQWgBMoKQAmUFYASKCsAJTgZ/3uOl+obmS+88MJO19u/f39nax09erSztfbs2dPZWpOTk52tdfvtt3e2liS18W93MUgy8iR0tqwAlEBZASiBsgJQAmUFoATKCkAJlBWAEigrACVQVgBKoKwAlNBkYMTrbP/G9u8G4+O/1kUwABjWZG7gfyRdmeSfg5Fcv7T9syS/bjkbALyqycCISPrn4OaKwcfSfFMSgEWr6ZDTZbb3Szoi6aEkI8fH25603d07RwH832hUVkn+m+S9ktZKusT2uhHPmUiyIcmGMWcEgIUdDUxyVNIjkq5uIwwAzKbJ0cA32149+PwsSR+S9FTLuQBghiZHA98m6R7byzRdbj9I8tN2YwHATE2OBv5e0voOsgDArDiDHUAJlBWAEigrACVQVgBKoKwAlEBZASiBsgJQAmUFoATGxy9i11xzTWdr3XPPPZ2ttWrVqs7W6tK2bds6Xa/L79nhw4c7W4vx8QBKo6wAlEBZASiBsgJQAmUFoATKCkAJlBWAEigrACVQVgBKoKwAlNC4rAaDTh+zzbAIAJ1byJbVzZIOtBUEAObSdHz8Wkkfl3Rnu3EAYLSmW1bbJX1F0onZnmB7q+1J25PjCAYAw5pMZP6EpCNJ9s71vCQTSTYk2TC2dAAw0GTLaqOkzbb/JOleSVfa/l6rqQDgFPOWVZJtSdYmOV/StZL2JNnSejIAGMJ5VgBKWL6QJyd5RNIjrSQBgDmwZQWgBMoKQAmUFYASKCsAJVBWAEqgrACUQFkBKIHx8ZAkrVu3rrO1tm/f3tlamzZt6mytrt1xxx2drXXbbbd1ss6RI0d07NgxxscDqIuyAlACZQWgBMoKQAmUFYASKCsAJVBWAEqgrACUQFkBKIGyAlBCo8saDybbvCzpv5KOM24LQNcWcg32Dyb5R2tJAGAO7AYCKKFpWUXSbtt7bW8d9QTGxwNoU9PdwI1JnrP9FkkP2X4qyS+Gn5BkQtKExCViAIxfoy2rJM8N/jwi6T5Jl7QZCgBONW9Z2V5pe9XJzyV9RNLjbQcDgGFNdgPfKuk+2yef//0kD7aaCgBOMW9ZJTkk6T0dZAGAWXHqAoASKCsAJVBWAEqgrACUQFkBKIGyAlACZQWgBMbHo3OrV6/ubK3Nmzd3ttbdd9/d2VqSNDhRuxN79uzpZJ0bb7xRBw8eZHw8gLooKwAlUFYASqCsAJRAWQEogbICUAJlBaAEygpACZQVgBIoKwAlNCor26tt77L9lO0Dti9vOxgADGs6N/Cbkh5M8inbr5V0douZAOA085aV7TdI+oCkz0hSkmOSjrUbCwBmarIb+A5Jz0v6ru3HbN85mB84A+PjAbSpSVktl/Q+Sd9Osl7SvyTdeuqTkkwk2ZBkw5gzAkCjspqSNJXk0cHtXZouLwDozLxlleRvkp61fdHgrk2Snmw1FQCcounRwC9I2jE4EnhI0mfbiwQAp2tUVkn2S+J3UQB6wxnsAEqgrACUQFkBKIGyAlACZQWgBMoKQAmUFYASKCsAJTjJ+L+oPf4vCixyr7zySqfrLV/e9A0oZ+748eOdrHPppZdq7969HvUYW1YASqCsAJRAWQEogbICUAJlBaAEygpACZQVgBIoKwAlUFYASpi3rGxfZHv/0MdLtm/pIBsAvGre8/WTHJT0XkmyvUzSXyXd124sAJhpobuBmyT9Mcmf2wgDALNZ6Dshr5W0c9QDtrdK2nrGiQBghMZbVoOZgZsl/XDU44yPB9CmhewGflTSviR/bysMAMxmIWV1nWbZBQSAtjUqK9tnS/qwpB+3GwcARms6Pv7fkt7UchYAmBVnsAMogbICUAJlBaAEygpACZQVgBIoKwAlUFYASqCsAJTQ1vzpf0ha6GVkzhn8vaVoqb42XteQFStWtBBl7Bb79+y82R5wki6DzMr25FK9YsNSfW28rnoqvzZ2AwGUQFkBKGExldVE3wFatFRfG6+rnrKvbdH8zgoA5rKYtqwAYFaUFYASFkVZ2b7a9kHbT9u+te8842D7XNsP2z5g+wnbN/edaZxsL7P9mO2f9p1lnGyvtr3L9lOD793lfWcaB9tfGvwcPm57p+3X9Z1poXovq8Hg1G9peiDFxZKus31xv6nG4rikLyd5t6TLJH1+ibyuk26WdKDvEC34pqQHk7xL0nu0BF6j7TWSvihpQ5J1kpZpeqxeKb2XlaRLJD2d5FCSY5LulfTJnjOdsSSHk+wbfP6ypn/o1/Sbajxsr5X0cUl39p1lnGy/QdIHJH1HkpIcS3K011Djs1zSWbaXSzpb0nM951mwxVBWayQ9O3R7SkvkH/VJts+XtF7Soz1HGZftkr4i6UTPOcbtHZKel/TdwS7unbZX9h3qTCX5q6SvS/qLpMOSXkyyu99UC7cYysoj7lsy51PYfr2kH0m6JclLfec5U7Y/IelIkr19Z2nBcknvk/TtJOsl/UtS+d+h2n6jpvdWLpD0dkkrbW/pN9XCLYaympJ07tDttSq4iTqK7RWaLqodSZbKGLONkjbb/pOmd9mvtP29fiONzZSkqSQnt4B3abq8qvuQpGeSPJ/kFU2P1Ht/z5kWbDGU1W8lvdP2BYMR9ddK+knPmc6YbWv6dx8Hknyj7zzjkmRbkrVJztf092pPknL/S4+S5G+SnrV90eCuTZKe7DHSuPxF0mW2zx78XG5SwQMHbV0iprEkx23fJOnnmj5KcVeSJ3qONQ4bJX1a0h9s7x/c99UkD/QXCQ18QdKOwX+chyR9tuc8ZyzJo7Z3Sdqn6aPUj6ng2254uw2AEhbDbiAAzIuyAlACZQWgBMoKQAmUFYASKCsAJVBWAEr4H2WZzko4p5l+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_tensor[0,10:18,10:20],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def split_indices(n,val_pct):\n",
    "    # Determine size of validation\n",
    "    n_val = int(val_pct*n)\n",
    "    #create random permutation of 0 to n-1\n",
    "    idxs = np.random.permutation(n)\n",
    "    # pick first n_val indices for validation set\n",
    "    return idxs[n_val:] , idxs[:n_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices , val_indices = split_indices(len(dataset),val_pct=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 12000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_indices),len(val_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample validation indices : [ 7234 17462 43486 34792  4443 24357 56683 53849 21052 51521 35024 54549\n",
      " 44137 42781 21053 23662  2483 57388 19950 58302]\n"
     ]
    }
   ],
   "source": [
    "print('Sample validation indices :',val_indices[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# traning sampler and data loader\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "train_loader = DataLoader(dataset,batch_size,sampler=train_sampler)\n",
    "\n",
    "# validation sampler and data loader\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "val_loader = DataLoader(dataset,batch_size,sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_size = 28*28 # each image is 28 X 28 Pixels \n",
    "num_classes = 10 # we want 10 class classifier\n",
    "# Logistic regression model\n",
    "model = nn.Linear(input_size,num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0217, -0.0010,  0.0330,  ..., -0.0338,  0.0123,  0.0158],\n",
       "        [-0.0005, -0.0003,  0.0080,  ..., -0.0265,  0.0174,  0.0347],\n",
       "        [ 0.0180,  0.0324,  0.0122,  ...,  0.0110,  0.0119,  0.0182],\n",
       "        ...,\n",
       "        [ 0.0278,  0.0216,  0.0144,  ..., -0.0066, -0.0039, -0.0046],\n",
       "        [ 0.0165, -0.0234, -0.0140,  ...,  0.0102, -0.0057, -0.0333],\n",
       "        [ 0.0252,  0.0129,  0.0149,  ...,  0.0126, -0.0051,  0.0056]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.weight.shape)\n",
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0299, -0.0145, -0.0270, -0.0019,  0.0097, -0.0157, -0.0310, -0.0317,\n",
       "         0.0167, -0.0334], requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.bias.shape)\n",
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4, 9, 1, 7, 9, 2, 3, 7, 2, 4, 7, 4, 0, 9, 9, 4, 0, 6, 1, 0, 5, 7, 4,\n",
      "        7, 2, 1, 6, 0, 7, 3, 3, 1, 8, 8, 2, 0, 2, 0, 2, 7, 8, 8, 4, 7, 7, 1, 3,\n",
      "        1, 6, 8, 7, 5, 1, 0, 5, 1, 9, 7, 8, 7, 7, 2, 1, 3, 1, 1, 4, 8, 0, 7, 6,\n",
      "        5, 8, 7, 4, 5, 5, 7, 9, 6, 9, 3, 1, 5, 8, 4, 9, 0, 8, 8, 1, 1, 1, 6, 6,\n",
      "        9, 8, 0, 6])\n",
      "torch.Size([100, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2800x28 and 784x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-76fd48d6cc56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1753\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2800x28 and 784x10)"
     ]
    }
   ],
   "source": [
    "for images , labels in train_loader:\n",
    "    print(labels)\n",
    "    print(images.shape)\n",
    "    outputs = model(images)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel (nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size,num_classes)\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1,784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "model = MnistModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784]) torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 3.0882e-02,  2.3654e-02,  6.5036e-05,  ...,  1.8945e-03,\n",
       "           2.4898e-02,  2.4908e-02],\n",
       "         [ 1.6901e-02,  1.5051e-02,  2.8067e-02,  ...,  1.1164e-02,\n",
       "          -2.8025e-02,  1.9563e-03],\n",
       "         [ 2.7879e-02,  1.2259e-02, -3.0292e-02,  ...,  7.3266e-03,\n",
       "          -3.8914e-03,  3.2536e-02],\n",
       "         ...,\n",
       "         [ 7.6133e-03,  3.5154e-02, -1.9071e-02,  ...,  1.0946e-02,\n",
       "           1.7908e-02,  2.6329e-03],\n",
       "         [ 1.6540e-02,  3.4435e-02,  1.6972e-02,  ..., -1.7516e-02,\n",
       "           1.9953e-02,  1.5761e-02],\n",
       "         [-2.2118e-02, -3.1093e-04,  3.5079e-02,  ..., -1.4651e-02,\n",
       "          -3.1057e-02,  1.6230e-03]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0065,  0.0237,  0.0325, -0.0313,  0.0078, -0.0024,  0.0086,  0.0221,\n",
       "          0.0265,  0.0096], requires_grad=True)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.linear.weight.shape,model.linear.bias.shape)\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output.shape: torch.Size([100, 10])\n",
      "Sample outputs:\n",
      " tensor([[-0.3322, -0.3167, -0.4098,  0.0396,  0.3996, -0.1430,  0.0510,  0.0071,\n",
      "          0.3350,  0.2893],\n",
      "        [ 0.2567, -0.2847, -0.3313, -0.0344,  0.2098, -0.3930,  0.2134,  0.0387,\n",
      "          0.2717,  0.1394]])\n"
     ]
    }
   ],
   "source": [
    "for images , labels in train_loader:\n",
    "    outputs = model(images)\n",
    "    break\n",
    "\n",
    "print('Output.shape:',outputs.shape)\n",
    "print('Sample outputs:\\n',outputs[:2].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Probability:\n",
      " tensor([[0.0696, 0.0707, 0.0644, 0.1010, 0.1448, 0.0841, 0.1022, 0.0978, 0.1357,\n",
      "         0.1297],\n",
      "        [0.1246, 0.0725, 0.0692, 0.0931, 0.1189, 0.0651, 0.1193, 0.1002, 0.1265,\n",
      "         0.1108]])\n",
      "Sum of Probability: 1.0000001192092896\n"
     ]
    }
   ],
   "source": [
    "# apply softmax for each output row\n",
    "probs = F.softmax(outputs,dim=1)\n",
    "\n",
    "# Look at sample probability\n",
    "print('Sample Probability:\\n',probs[:2].data)\n",
    "\n",
    "# add up the probabilities of an output row\n",
    "print('Sum of Probability:',torch.sum(probs[0]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 8, 5, 4, 3, 7, 3, 6, 8, 4, 9, 3, 4, 4, 5, 4, 6, 7, 9, 3, 6, 3, 3, 3,\n",
      "        4, 6, 8, 8, 8, 8, 9, 4, 6, 2, 5, 7, 6, 3, 9, 8, 9, 5, 8, 5, 9, 8, 6, 4,\n",
      "        4, 9, 8, 5, 7, 8, 7, 8, 5, 8, 7, 0, 8, 5, 7, 4, 9, 4, 0, 0, 9, 4, 6, 8,\n",
      "        3, 0, 0, 6, 4, 4, 5, 7, 8, 8, 4, 0, 3, 5, 5, 4, 8, 4, 6, 6, 2, 4, 8, 0,\n",
      "        5, 3, 7, 0])\n",
      "tensor([0.1448, 0.1265, 0.1307, 0.1284, 0.1447, 0.1313, 0.1326, 0.1366, 0.1444,\n",
      "        0.1580, 0.1291, 0.1473, 0.1707, 0.1518, 0.1246, 0.1295, 0.1377, 0.1488,\n",
      "        0.1163, 0.1207, 0.1186, 0.1216, 0.1317, 0.1244, 0.1517, 0.1324, 0.1222,\n",
      "        0.1347, 0.1277, 0.1284, 0.1181, 0.1185, 0.1295, 0.1122, 0.1362, 0.1107,\n",
      "        0.1161, 0.1262, 0.1329, 0.1340, 0.1268, 0.1201, 0.1255, 0.1475, 0.1355,\n",
      "        0.1214, 0.1350, 0.1245, 0.1322, 0.1234, 0.1158, 0.1230, 0.1256, 0.1414,\n",
      "        0.1368, 0.1285, 0.1207, 0.1181, 0.1275, 0.1265, 0.1300, 0.1265, 0.1233,\n",
      "        0.1418, 0.1514, 0.1291, 0.1280, 0.1257, 0.1137, 0.1421, 0.1244, 0.1318,\n",
      "        0.1288, 0.1197, 0.1206, 0.1315, 0.1390, 0.1339, 0.1496, 0.1300, 0.1202,\n",
      "        0.1429, 0.1360, 0.1322, 0.1266, 0.1188, 0.1288, 0.1353, 0.1500, 0.1310,\n",
      "        0.1202, 0.1209, 0.1139, 0.1338, 0.1286, 0.1261, 0.1110, 0.1303, 0.1294,\n",
      "        0.1408], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "max_probs , preds = torch.max(probs,dim=1)\n",
    "print(preds)\n",
    "print(max_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 6, 6, 4, 0, 8, 6, 3, 7, 6, 6, 7, 4, 2, 0, 4, 0, 4, 5, 1, 2, 6, 8,\n",
       "        3, 9, 3, 4, 3, 8, 3, 8, 9, 1, 6, 2, 9, 0, 3, 9, 8, 4, 8, 6, 3, 5, 6, 5,\n",
       "        5, 9, 1, 9, 5, 3, 8, 9, 1, 2, 8, 5, 5, 2, 3, 5, 2, 8, 3, 5, 1, 7, 4, 9,\n",
       "        5, 0, 3, 8, 7, 0, 6, 5, 1, 3, 8, 0, 6, 1, 2, 3, 8, 5, 4, 6, 3, 8, 4, 9,\n",
       "        6, 0, 4, 6])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
